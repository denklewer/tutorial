{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "exercise09-GPUs.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2HaOAtXm3Ku",
        "colab_type": "text"
      },
      "source": [
        "# Exercise 9 - Using the GPU API\n",
        "\n",
        "**GOAL:** The goal of this exercise is to show how to use GPUs with remote functions and actors.\n",
        "\n",
        "**NOTE:** These exercises are designed to run on a machine without GPUs.\n",
        "\n",
        "See the documentation on using Ray with GPUs http://ray.readthedocs.io/en/latest/using-ray-with-gpus.html.\n",
        "\n",
        "### Concepts for this Exercise - Using Ray with GPUs\n",
        "\n",
        "We can indicate that a remote function or an actor requires some GPUs using the `num_gpus` keyword.\n",
        "\n",
        "```python\n",
        "@ray.remote(num_gpus=1)\n",
        "def f():\n",
        "    # The command ray.get_gpu_ids() returns a list of the indices\n",
        "    # of the GPUs that this task can use (e.g., [0] or [1]).\n",
        "    ray.get_gpu_ids()\n",
        "\n",
        "@ray.remote(num_gpus=2)\n",
        "class Foo(object):\n",
        "    def __init__(self):\n",
        "        # The command ray.get_gpu_ids() returns a list of the\n",
        "        # indices of the GPUs that this actor can use\n",
        "        # (e.g., [0, 1] or [3, 5]).\n",
        "        ray.get_gpu_ids()\n",
        "```\n",
        "\n",
        "Then inside of the actor constructor and methods, we can get the IDs of the GPUs allocated for that actor with `ray.get_gpu_ids()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJw5hlVLnGAo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8f351fcd-f7bc-472c-a95e-d9b5b88f4548"
      },
      "source": [
        "import os\n",
        "os.system('pip install ray')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtJHfEKKm3K0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import ray\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgMe4YJsm3LD",
        "colab_type": "text"
      },
      "source": [
        "Start Ray, note that we pass in `num_gpus=4`. Ray will assume this machine has 4 GPUs (even if it does not). When a task or actor requests a GPU, it will be assigned a GPU ID from the set `[0, 1, 2, 3]`. It is then the responsibility of the task or actor to make sure that it only uses that specific GPU (e.g., by setting the `CUDA_VISIBLE_DEVICES` environment variable)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdR4CbKjm3LG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "279474fe-1dde-4ae9-e557-91ce033eea94"
      },
      "source": [
        "ray.init(num_cpus=4, num_gpus=2, include_webui=False, ignore_reinit_error=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-05-16 12:28:30,610\tWARNING worker.py:1337 -- WARNING: Not updating worker name since `setproctitle` is not installed. Install this with `pip install setproctitle` (or ray[debug]) to enable monitoring of worker processes.\n",
            "2019-05-16 12:28:30,613\tINFO node.py:469 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-05-16_12-28-30_133/logs.\n",
            "2019-05-16 12:28:30,727\tINFO services.py:407 -- Waiting for redis server at 127.0.0.1:16394 to respond...\n",
            "2019-05-16 12:28:30,854\tINFO services.py:407 -- Waiting for redis server at 127.0.0.1:55537 to respond...\n",
            "2019-05-16 12:28:30,857\tINFO services.py:804 -- Starting Redis shard with 2.52 GB max memory.\n",
            "2019-05-16 12:28:30,885\tINFO node.py:483 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-05-16_12-28-30_133/logs.\n",
            "2019-05-16 12:28:30,887\tINFO services.py:1427 -- Starting the Plasma object store with 3.78 GB memory using /dev/shm.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'node_ip_address': '172.28.0.2',\n",
              " 'object_store_address': '/tmp/ray/session_2019-05-16_12-28-30_133/sockets/plasma_store',\n",
              " 'raylet_socket_name': '/tmp/ray/session_2019-05-16_12-28-30_133/sockets/raylet',\n",
              " 'redis_address': '172.28.0.2:16394',\n",
              " 'webui_url': None}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64lq38fwm3LT",
        "colab_type": "text"
      },
      "source": [
        "**EXERCISE:** Change the remote function below to require one GPU.\n",
        "\n",
        "**NOTE:** This change does not make the remote function actually **use** the GPU, it simply **reserves** the GPU for use by the remote function. To actually use the GPU, the remote function would use a neural net library like TensorFlow or PyTorch after setting the `CUDA_VISIBLE_DEVICES` environment variable properly. This can be done as follows.\n",
        "\n",
        "```python\n",
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = ','.join([str(i) for i in ray.get_gpu_ids()])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPijtTtlnjpV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ['CUDA_VISIBLE_DEVICES'] = ','.join([str(i) for i in ray.get_gpu_ids()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vz1N54Zpm3LW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@ray.remote(num_gpus=1)\n",
        "def f():\n",
        "    time.sleep(0.5)\n",
        "    return ray.get_gpu_ids()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQVb_jQ4m3Li",
        "colab_type": "text"
      },
      "source": [
        "**VERIFY:** This code checks that each task was assigned one GPU and that not more than two tasks are run at the same time (because we told Ray there are only two GPUs)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPk_FSyym3Lk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a4257371-a62d-490d-8c80-e08e8439bb96"
      },
      "source": [
        "start_time = time.time()\n",
        "\n",
        "gpu_ids = ray.get([f.remote() for _ in range(3)])\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "for i in range(len(gpu_ids)):\n",
        "    assert len(gpu_ids[i]) == 1\n",
        "\n",
        "assert end_time - start_time > 1\n",
        "\n",
        "print('Sucess! The test passed.')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sucess! The test passed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYIbe_uGm3Lz",
        "colab_type": "text"
      },
      "source": [
        "**EXERCISE:** The code below defines an actor. Make it require one GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cwIc12ym3L2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@ray.remote(num_gpus=1)\n",
        "class Actor(object):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def get_gpu_ids(self):\n",
        "        return ray.get_gpu_ids()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5tmjnm_m3L_",
        "colab_type": "text"
      },
      "source": [
        "**VERIFY:** This code checks that the actor was assigned a GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PUq5FTDm3ME",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b2c709e4-92bf-4d75-ec57-e4fa57fd2440"
      },
      "source": [
        "actor = Actor.remote()\n",
        "\n",
        "gpu_ids = ray.get(actor.get_gpu_ids.remote())\n",
        "\n",
        "assert len(gpu_ids) == 1\n",
        "\n",
        "print('Sucess! The test passed.')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sucess! The test passed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkQHzrkUm3MQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8c2d70ef-9027-487b-f5ad-b1ac81e497e6"
      },
      "source": [
        "gpu_ids"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZxMnEHpoGmA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}