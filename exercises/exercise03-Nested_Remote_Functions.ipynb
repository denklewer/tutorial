{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "exercise03-Nested_Remote_Functions.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTeFHgf6VT_E",
        "colab_type": "text"
      },
      "source": [
        "# Exercise 3 - Nested Parallelism\n",
        "\n",
        "**GOAL:** The goal of this exercise is to show how to create nested tasks by calling a remote function inside of another remote function.\n",
        "\n",
        "In this exercise, you will implement the structure of a parallel hyperparameter sweep which trains a number of models in parallel. Each model will be trained using parallel gradient computations.\n",
        "\n",
        "### Concepts for this Exercise - Nested Remote Functions\n",
        "\n",
        "Remote functions can call other functions. For example, consider the following.\n",
        "\n",
        "```python\n",
        "@ray.remote\n",
        "def f():\n",
        "    return 1\n",
        "\n",
        "@ray.remote\n",
        "def g():\n",
        "    # Call f 4 times and return the resulting object IDs.\n",
        "    return [f.remote() for _ in range(4)]\n",
        "\n",
        "@ray.remote\n",
        "def h():\n",
        "    # Call f 4 times, block until those 4 tasks finish,\n",
        "    # retrieve the results, and return the values.\n",
        "    return ray.get([f.remote() for _ in range(4)])\n",
        "```\n",
        "\n",
        "Then calling `g` and `h` produces the following behavior.\n",
        "\n",
        "```python\n",
        ">>> ray.get(g.remote())\n",
        "[ObjectID(b1457ba0911ae84989aae86f89409e953dd9a80e),\n",
        " ObjectID(7c14a1d13a56d8dc01e800761a66f09201104275),\n",
        " ObjectID(99763728ffc1a2c0766a2000ebabded52514e9a6),\n",
        " ObjectID(9c2f372e1933b04b2936bb6f58161285829b9914)]\n",
        "\n",
        ">>> ray.get(h.remote())\n",
        "[1, 1, 1, 1]\n",
        "```\n",
        "\n",
        "**One limitation** is that the definition of `f` must come before the definitions of `g` and `h` because as soon as `g` is defined, it will be pickled and shipped to the workers, and so if `f` hasn't been defined yet, the definition will be incomplete."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4yI4vn9VVmN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a45f4d80-d2de-4fac-9f32-0c594454b8ea"
      },
      "source": [
        "import os\n",
        "os.system('pip install ray')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLyDPTE9VT_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import ray\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tSlYGK3VT_a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "5442202b-7a80-43a3-bc3c-ddac8ea77af1"
      },
      "source": [
        "ray.init(num_cpus=9, include_webui=False, ignore_reinit_error=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-05-16 11:11:13,995\tWARNING worker.py:1337 -- WARNING: Not updating worker name since `setproctitle` is not installed. Install this with `pip install setproctitle` (or ray[debug]) to enable monitoring of worker processes.\n",
            "2019-05-16 11:11:14,000\tINFO node.py:469 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-05-16_11-11-13_117/logs.\n",
            "2019-05-16 11:11:14,116\tINFO services.py:407 -- Waiting for redis server at 127.0.0.1:16920 to respond...\n",
            "2019-05-16 11:11:14,248\tINFO services.py:407 -- Waiting for redis server at 127.0.0.1:23464 to respond...\n",
            "2019-05-16 11:11:14,251\tINFO services.py:804 -- Starting Redis shard with 2.58 GB max memory.\n",
            "2019-05-16 11:11:14,287\tINFO node.py:483 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-05-16_11-11-13_117/logs.\n",
            "2019-05-16 11:11:14,290\tINFO services.py:1427 -- Starting the Plasma object store with 3.87 GB memory using /dev/shm.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'node_ip_address': '172.28.0.2',\n",
              " 'object_store_address': '/tmp/ray/session_2019-05-16_11-11-13_117/sockets/plasma_store',\n",
              " 'raylet_socket_name': '/tmp/ray/session_2019-05-16_11-11-13_117/sockets/raylet',\n",
              " 'redis_address': '172.28.0.2:16920',\n",
              " 'webui_url': None}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOHbAqgCVT_k",
        "colab_type": "text"
      },
      "source": [
        "This example represents a hyperparameter sweep in which multiple models are trained in parallel. Each model training task also performs data parallel gradient computations.\n",
        "\n",
        "**EXERCISE:** Turn `compute_gradient` and `train_model` into remote functions so that they can be executed in parallel. Inside of `train_model`, do the calls to `compute_gradient` in parallel and fetch the results using `ray.get`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UCZ3ZQPVT_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@ray.remote\n",
        "def compute_gradient(data, current_model):\n",
        "    time.sleep(0.03)\n",
        "    return 1\n",
        "\n",
        "@ray.remote\n",
        "def train_model(hyperparameters):\n",
        "    current_model = 0\n",
        "    # Iteratively improve the current model. This outer loop cannot be parallelized.\n",
        "    for _ in range(10):\n",
        "        # EXERCISE: Parallelize the list comprehension in the line below. After you\n",
        "        # turn \"compute_gradient\" into a remote function, you will need to call it\n",
        "        # with \".remote\". The results must be retrieved with \"ray.get\" before \"sum\"\n",
        "        # is called.\n",
        "        total_gradient = sum(ray.get([compute_gradient.remote(j, current_model) for j in range(2)]))\n",
        "        current_model += total_gradient\n",
        "\n",
        "    return current_model\n",
        "\n",
        "assert hasattr(compute_gradient, 'remote'), 'compute_gradient must be a remote function'\n",
        "assert hasattr(train_model, 'remote'), 'train_model must be a remote function'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_mY3zFvVT_z",
        "colab_type": "text"
      },
      "source": [
        "**EXERCISE:** The code below runs 3 hyperparameter experiments. Change this to run the experiments in parallel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVQBQSefVT_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sleep a little to improve the accuracy of the timing measurements below.\n",
        "time.sleep(2.0)\n",
        "start_time = time.time()\n",
        "\n",
        "# Run some hyperparaameter experiments.\n",
        "results = []\n",
        "for hyperparameters in [{'learning_rate': 1e-1, 'batch_size': 100},\n",
        "                        {'learning_rate': 1e-2, 'batch_size': 100},\n",
        "                        {'learning_rate': 1e-3, 'batch_size': 100}]:\n",
        "    results.append(train_model.remote(hyperparameters))\n",
        "\n",
        "# EXERCISE: Once you've turned \"results\" into a list of Ray ObjectIDs\n",
        "# by calling train_model.remote, you will need to turn \"results\" back\n",
        "# into a list of integers, e.g., by doing \"results = ray.get(results)\".\n",
        "results = ray.get(results)\n",
        "end_time = time.time()\n",
        "duration = end_time - start_time\n",
        "\n",
        "assert all([isinstance(x, int) for x in results]), \\\n",
        "    'Looks like \"results\" is {}. You may have forgotten to call ray.get.'.format(results)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BXdQLxuVT_-",
        "colab_type": "text"
      },
      "source": [
        "**VERIFY:** Run some checks to verify that the changes you made to the code were correct. Some of the checks should fail when you initially run the cells. After completing the exercises, the checks should pass.\n",
        "\n",
        "**NOTE:** This exercise is known to have issues on binder that can be resolved by rerunning the above cell a second time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ERprJzwVUAB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6bac2c17-aecb-400a-d6c7-d1c9d3faccaa"
      },
      "source": [
        "assert results == [20, 20, 20]\n",
        "assert duration < 0.5, ('The experiments ran in {} seconds. This is too '\n",
        "                         'slow.'.format(duration))\n",
        "assert duration > 0.3, ('The experiments ran in {} seconds. This is too '\n",
        "                        'fast.'.format(duration))\n",
        "\n",
        "print('Success! The example took {} seconds.'.format(duration))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Success! The example took 0.3473038673400879 seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PzM4q1uVUAH",
        "colab_type": "text"
      },
      "source": [
        "**EXERCISE:** Use the UI to view the task timeline and to verify that the pattern makes sense."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLhexGAZVUAK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ray.global_state.chrome_tracing_dump(filename=\"/tmp/timeline03.json\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78tvgnelVUAg",
        "colab_type": "text"
      },
      "source": [
        "Download link for Binder: http://localhost:8000/timeline03.json"
      ]
    }
  ]
}